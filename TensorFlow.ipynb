{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import utils.reader as reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '../input/fashion-mnist_train.csv'\n",
    "test_file = '../input/fashion-mnist_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './fashion-model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000022106C09588>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column('pixels', shape=[28,28])]\n",
    "classifier = tf.estimator.LinearClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    n_classes=10,\n",
    "    model_dir='./fashion-model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labelled_input_fn(csv_files, batch_size):\n",
    "    def input_fn():\n",
    "        file_queue = tf.train.string_input_producer(csv_files)\n",
    "        textLine_reader = tf.TextLineReader(skip_header_lines=1)\n",
    "        _, rows = textLine_reader.read_up_to(file_queue, num_records=100*batch_size)\n",
    "        expanded_rows = tf.expand_dims(rows, axis=-1)\n",
    "        \n",
    "        shuffled_rows = tf.train.shuffle_batch(\n",
    "            [expanded_rows],\n",
    "            batch_size=batch_size,\n",
    "            capacity=20*batch_size,\n",
    "            min_after_dequeue=5*batch_size,\n",
    "            enqueue_many=True\n",
    "        )\n",
    "\n",
    "        record_defaults = [[0] for _ in range(28*28+1)]\n",
    "\n",
    "        columns = tf.decode_csv(shuffled_rows, record_defaults=record_defaults)\n",
    "\n",
    "        labels = columns[0]\n",
    "\n",
    "        pixels = tf.concat(columns[1:], axis=1)\n",
    "\n",
    "        return {'pixels': pixels}, labels\n",
    "    \n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 40\n",
    "TRAIN_STEPS = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./fashion-model\\model.ckpt-37000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 37001 into ./fashion-model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 461.52597, step = 37001\n",
      "INFO:tensorflow:global_step/sec: 44.4599\n",
      "INFO:tensorflow:loss = 387.54587, step = 37101 (2.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.5124\n",
      "INFO:tensorflow:loss = 173.80042, step = 37201 (1.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.4485\n",
      "INFO:tensorflow:loss = 1096.4036, step = 37301 (1.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.7706\n",
      "INFO:tensorflow:loss = 484.35614, step = 37401 (1.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.8016\n",
      "INFO:tensorflow:loss = 1139.1398, step = 37501 (1.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.484\n",
      "INFO:tensorflow:loss = 488.5569, step = 37601 (1.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.7756\n",
      "INFO:tensorflow:loss = 373.63925, step = 37701 (1.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.3643\n",
      "INFO:tensorflow:loss = 693.75757, step = 37801 (1.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.9765\n",
      "INFO:tensorflow:loss = 352.08447, step = 37901 (1.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5756\n",
      "INFO:tensorflow:loss = 306.48535, step = 38001 (1.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.5124\n",
      "INFO:tensorflow:loss = 759.28235, step = 38101 (1.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.9419\n",
      "INFO:tensorflow:loss = 285.4665, step = 38201 (1.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.9776\n",
      "INFO:tensorflow:loss = 361.33313, step = 38301 (1.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.4236\n",
      "INFO:tensorflow:loss = 479.81934, step = 38401 (1.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.7067\n",
      "INFO:tensorflow:loss = 439.50604, step = 38501 (1.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.1594\n",
      "INFO:tensorflow:loss = 513.05, step = 38601 (1.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.7992\n",
      "INFO:tensorflow:loss = 552.9073, step = 38701 (1.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.742\n",
      "INFO:tensorflow:loss = 1013.3729, step = 38801 (1.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.8807\n",
      "INFO:tensorflow:loss = 1271.4453, step = 38901 (1.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.9232\n",
      "INFO:tensorflow:loss = 341.31952, step = 39001 (1.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.6455\n",
      "INFO:tensorflow:loss = 1009.6929, step = 39101 (1.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.628\n",
      "INFO:tensorflow:loss = 483.78796, step = 39201 (1.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.7074\n",
      "INFO:tensorflow:loss = 1539.7744, step = 39301 (1.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.8994\n",
      "INFO:tensorflow:loss = 336.11887, step = 39401 (1.075 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 39500 into ./fashion-model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 571.58527.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x22177fcf0f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(\n",
    "    input_fn=generate_labelled_input_fn([train_file], BATCH_SIZE),\n",
    "    steps=TRAIN_STEPS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-06-06:36:11\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./fashion-model\\model.ckpt-39500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-06-06:36:14\n",
      "INFO:tensorflow:Saving dict for global step 39500: accuracy = 0.8055, average_loss = 18.70167, global_step = 39500, loss = 748.0668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8055,\n",
       " 'average_loss': 18.70167,\n",
       " 'global_step': 39500,\n",
       " 'loss': 748.0668}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(\n",
    "    input_fn=generate_labelled_input_fn([test_file], BATCH_SIZE),\n",
    "    steps=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = {\n",
    "    '0': 'T-shirt/top',\n",
    "    '1': 'Trouser',\n",
    "    '2': 'Pullover',\n",
    "    '3': 'Dress',\n",
    "    '4': 'Coat',\n",
    "    '5': 'Sandal',\n",
    "    '6': 'Shirt',\n",
    "    '7': 'Sneaker',\n",
    "    '8': 'Bag',\n",
    "    '9': 'Ankle boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22193306630>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x221767c2d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = pd.read_csv(test_file)\n",
    "sample_data = test_data.sample()\n",
    "\n",
    "sample = list(sample_data.iloc[0])\n",
    "label = sample[0]\n",
    "pixels = sample[1:]\n",
    "\n",
    "image_array = np.asarray(pixels, dtype=np.float32).reshape((28, 28))\n",
    "plt.imshow(image_array, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction_input_fn(image_arrays):\n",
    "    def input_fn():\n",
    "        queue = tf.train.input_producer(\n",
    "            tf.constant(np.asarray(image_arrays)),\n",
    "            num_epochs=1\n",
    "        )\n",
    "        \n",
    "        image = queue.dequeue()\n",
    "        return {'pixels': [image]}\n",
    "    \n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(\n",
    "    generate_prediction_input_fn([image_array]),\n",
    "    predict_keys=['probabilities', 'classes']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./fashion-model\\model.ckpt-39500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "prediction = next(predictions)\n",
    "# print('Prediction output: {}'.format(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probabilities': array([1.0000000e+00, 0.0000000e+00, 2.2853594e-14, 0.0000000e+00,\n",
      "       0.0000000e+00, 0.0000000e+00, 2.2856651e-36, 0.0000000e+00,\n",
      "       0.0000000e+00, 0.0000000e+00], dtype=float32), 'classes': array([b'0'], dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label: 2 - Pullover\n",
      "Predicted class: 0 - T-shirt/top with probability 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Actual label: {} - {}'.format(label, CLASSES[str(label)]))\n",
    "predicted_class = prediction['classes'][0].decode('utf-8')\n",
    "probability = prediction['probabilities'][int(predicted_class)]\n",
    "print('Predicted class: {} - {} with probability {}'.format(\n",
    "    predicted_class,\n",
    "    CLASSES[predicted_class],\n",
    "    probability\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
